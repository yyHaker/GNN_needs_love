{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using backend: pytorch\n"
    }
   ],
   "source": [
    "# Each value of the dictionary is a pair of source and destination arrays.\n",
    "# Nodes are integer IDs starting from zero. Nodes IDs of different types have\n",
    "# separate countings.\n",
    "import dgl\n",
    "import numpy as np\n",
    "\n",
    "ratings = dgl.heterograph(\n",
    "    {('user', '+1', 'movie') : (np.array([0, 0, 1]), np.array([0, 1, 0])),\n",
    "     ('user', '-1', 'movie') : (np.array([2]), np.array([1]))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['__header__', '__version__', '__globals__', 'TvsP', 'PvsA', 'PvsV', 'AvsF', 'VvsC', 'PvsL', 'PvsC', 'A', 'C', 'F', 'L', 'P', 'T', 'V', 'PvsT', 'CNormPvsA', 'RNormPvsA', 'CNormPvsC', 'RNormPvsC', 'CNormPvsT', 'RNormPvsT', 'CNormPvsV', 'RNormPvsV', 'CNormVvsC', 'RNormVvsC', 'CNormAvsF', 'RNormAvsF', 'CNormPvsL', 'RNormPvsL', 'stopwords', 'nPvsT', 'nT', 'CNormnPvsT', 'RNormnPvsT', 'nnPvsT', 'nnT', 'CNormnnPvsT', 'RNormnnPvsT', 'PvsP', 'CNormPvsP', 'RNormPvsP']\n<class 'scipy.sparse.csc.csc_matrix'>\n#Papers: 12499\n#Authors: 17431\n#Links: 37055\n"
    }
   ],
   "source": [
    "# download ACM dataset\n",
    "import scipy.io\n",
    "import urllib.request\n",
    "\n",
    "data_url = 'https://data.dgl.ai/dataset/ACM.mat'\n",
    "data_file_path = '/tmp/ACM.mat'\n",
    "\n",
    "urllib.request.urlretrieve(data_url, data_file_path)\n",
    "data = scipy.io.loadmat(data_file_path)\n",
    "print(list(data.keys()))\n",
    "\n",
    "print(type(data['PvsA']))\n",
    "print('#Papers:', data['PvsA'].shape[0])\n",
    "print('#Authors:', data['PvsA'].shape[1])\n",
    "print('#Links:', data['PvsA'].nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Node types: ['author', 'paper']\nEdge types: ['written-by']\nCanonical edge types: [('paper', 'written-by', 'author')]\n12499\n37055\n37055\ntensor([3532, 6421, 8516, 8560])\n37055\n"
    }
   ],
   "source": [
    "# Converting this SciPy matrix to a heterograph in DGL\n",
    "pa_g = dgl.heterograph({('paper', 'written-by', 'author') : data['PvsA'].nonzero()})\n",
    "\n",
    "print('Node types:', pa_g.ntypes)\n",
    "print('Edge types:', pa_g.etypes)\n",
    "print('Canonical edge types:', pa_g.canonical_etypes)\n",
    "\n",
    "# Nodes and edges are assigned integer IDs starting from zero and each type has its own counting.\n",
    "# To distinguish the nodes and edges of different types, specify the type name as the argument.\n",
    "print(pa_g.number_of_nodes('paper'))\n",
    "# Canonical edge type name can be shortened to only one edge type name if it is\n",
    "# uniquely distinguishable.\n",
    "print(pa_g.number_of_edges(('paper', 'written-by', 'author')))\n",
    "print(pa_g.number_of_edges('written-by'))\n",
    "print(pa_g.successors(1, etype='written-by'))  # get the authors that write paper #1\n",
    "\n",
    "# Type name argument could be omitted whenever the behavior is unambiguous.\n",
    "print(pa_g.number_of_edges())  # Only one edge type, the edge type argument could be omitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "12499\n30789\ntensor([1361, 2624, 8670, 9845])\n"
    }
   ],
   "source": [
    "# A homogeneous graph is just a special case of a heterograph with only one type of node and edge.\n",
    "# Paper-citing-paper graph is a homogeneous graph\n",
    "pp_g = dgl.heterograph({('paper', 'citing', 'paper') : data['PvsP'].nonzero()})\n",
    "# equivalent (shorter) API for creating homogeneous graph\n",
    "pp_g = dgl.from_scipy(data['PvsP'])\n",
    "\n",
    "# All the ntype and etype arguments could be omitted because the behavior is unambiguous.\n",
    "print(pp_g.number_of_nodes())\n",
    "print(pp_g.number_of_edges())\n",
    "print(pp_g.successors(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Graph(num_nodes={'author': 17431, 'paper': 12499, 'subject': 73},\n      num_edges={('author', 'writing', 'paper'): 37055, ('paper', 'cited', 'paper'): 30789, ('paper', 'citing', 'paper'): 30789, ('paper', 'is-about', 'subject'): 12499, ('paper', 'written-by', 'author'): 37055, ('subject', 'has', 'paper'): 12499},\n      metagraph=[('author', 'paper', 'writing'), ('paper', 'paper', 'cited'), ('paper', 'paper', 'citing'), ('paper', 'subject', 'is-about'), ('paper', 'author', 'written-by'), ('subject', 'paper', 'has')])\n"
    }
   ],
   "source": [
    "# Create a subset of the ACM graph using the paper-author, paper-paper, \n",
    "# and paper-subject relationships. Meanwhile, also add the reverse relationship to prepare for the later sections.\n",
    "G = dgl.heterograph({\n",
    "        ('paper', 'written-by', 'author') : data['PvsA'].nonzero(),\n",
    "        ('author', 'writing', 'paper') : data['PvsA'].transpose().nonzero(),\n",
    "        ('paper', 'citing', 'paper') : data['PvsP'].nonzero(),\n",
    "        ('paper', 'cited', 'paper') : data['PvsP'].transpose().nonzero(),\n",
    "        ('paper', 'is-about', 'subject') : data['PvsL'].nonzero(),\n",
    "        ('subject', 'has', 'paper') : data['PvsL'].transpose().nonzero(),\n",
    "    })\n",
    "\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pygraphviz'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-867c2acee724>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Draw the metagraph using graphviz.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpygraphviz\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpgv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnxg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnxg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pygraphviz'"
     ]
    }
   ],
   "source": [
    "# Draw the metagraph using graphviz.\n",
    "import pygraphviz as pgv\n",
    "def plot_graph(nxg):\n",
    "    ag = pgv.AGraph(strict=False, directed=True)\n",
    "    for u, v, k in nxg.edges(keys=True):\n",
    "        ag.add_edge(u, v, label=k)\n",
    "    ag.layout('dot')\n",
    "    ag.draw('graph.png')\n",
    "\n",
    "plot_graph(G.metagraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "p_selected shape:  (12499, 3)\n  (0, 0)\t1.0\n  (1, 0)\t1.0\n  (2, 0)\t1.0\n  (3, 0)\t1.0\n  (4, 0)\t1.0\n  (5, 0)\t1.0\n  (6, 0)\t1.0\n  (7, 0)\t1.0\n  (8, 0)\t1.0\n  (9, 0)\t1.0\n  (10, 0)\t1.0\n  (11, 0)\t1.0\n  (12, 0)\t1.0\n  (13, 0)\t1.0\n  (14, 0)\t1.0\n  (15, 0)\t1.0\n  (16, 0)\t1.0\n  (17, 0)\t1.0\n  (18, 0)\t1.0\n  (19, 0)\t1.0\n  (20, 0)\t1.0\n  (21, 0)\t1.0\n  (22, 0)\t1.0\n  (23, 0)\t1.0\n  (24, 0)\t1.0\n  :\t:\n  (10783, 0)\t1.0\n  (10784, 0)\t1.0\n  (10785, 0)\t1.0\n  (10786, 0)\t1.0\n  (10787, 0)\t1.0\n  (10788, 0)\t1.0\n  (10789, 0)\t1.0\n  (10790, 0)\t1.0\n  (10791, 0)\t1.0\n  (10792, 0)\t1.0\n  (10793, 0)\t1.0\n  (10794, 0)\t1.0\n  (10795, 0)\t1.0\n  (10796, 0)\t1.0\n  (10797, 0)\t1.0\n  (10798, 0)\t1.0\n  (10799, 0)\t1.0\n  (10800, 0)\t1.0\n  (10801, 0)\t1.0\n  (10802, 0)\t1.0\n  (10803, 0)\t1.0\n  (10804, 0)\t1.0\n  (10805, 0)\t1.0\n  (10806, 0)\t1.0\n  (12420, 1)\t1.0\n"
    }
   ],
   "source": [
    "# A semi-supervised node classification example\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "pvc = data['PvsC'].tocsr()\n",
    "# find all papers published in KDD, ICML, VLDB\n",
    "c_selected = [0, 11, 13]  # KDD, ICML, VLDB\n",
    "p_selected = pvc[:, c_selected].tocoo()\n",
    "print(\"p_selected shape: \", p_selected.shape)\n",
    "\n",
    "# generate labels\n",
    "labels = pvc.indices\n",
    "labels[labels == 11] = 1\n",
    "labels[labels == 13] = 2\n",
    "labels = torch.tensor(labels).long()\n",
    "# print(labels, labels.shape)\n",
    "\n",
    "# generate train/val/test split\n",
    "pid = p_selected.row\n",
    "shuffle = np.random.permutation(pid)\n",
    "train_idx = torch.tensor(shuffle[0:800]).long()\n",
    "val_idx = torch.tensor(shuffle[800:900]).long()\n",
    "test_idx = torch.tensor(shuffle[900:]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "import torch.nn as nn\n",
    "\n",
    "class HeteroRGCNLayer(nn.Module):\n",
    "    def __init__(self, in_size, out_size, etypes):\n",
    "        super(HeteroRGCNLayer, self).__init__()\n",
    "        # W_r for each relation\n",
    "        self.weight = nn.ModuleDict({\n",
    "                name : nn.Linear(in_size, out_size) for name in etypes\n",
    "            })\n",
    "\n",
    "    def forward(self, G, feat_dict):\n",
    "        # The input is a dictionary of node features for each type\n",
    "        funcs = {}\n",
    "        for srctype, etype, dsttype in G.canonical_etypes:\n",
    "            # Compute W_r * h\n",
    "            Wh = self.weight[etype](feat_dict[srctype])\n",
    "            # Save it in graph for message passing\n",
    "            G.nodes[srctype].data['Wh_%s' % etype] = Wh\n",
    "            # Specify per-relation message passing functions: (message_func, reduce_func).\n",
    "            # Note that the results are saved to the same destination feature 'h', which\n",
    "            # hints the type wise reducer for aggregation.\n",
    "            funcs[etype] = (fn.copy_u('Wh_%s' % etype, 'm'), fn.mean('m', 'h'))\n",
    "        # Trigger message passing of multiple types.\n",
    "        # The first argument is the message passing functions for each relation.\n",
    "        # The second one is the type wise reducer, could be \"sum\", \"max\",\n",
    "        # \"min\", \"mean\", \"stack\"\n",
    "        G.multi_update_all(funcs, 'sum')\n",
    "        # return the updated node feature dictionary\n",
    "        return {ntype : G.nodes[ntype].data['h'] for ntype in G.ntypes}\n",
    "\n",
    "# Create a simple GNN by stacking two HeteroRGCNLayer\n",
    "class HeteroRGCN(nn.Module):\n",
    "    def __init__(self, G, in_size, hidden_size, out_size):\n",
    "        super(HeteroRGCN, self).__init__()\n",
    "        # Use trainable node embeddings as featureless inputs.\n",
    "        embed_dict = {ntype : nn.Parameter(torch.Tensor(G.number_of_nodes(ntype), in_size)) \n",
    "                        for ntype in G.ntypes}\n",
    "\n",
    "        for key, embed in embed_dict.items():\n",
    "             nn.init.xavier_uniform_(embed)\n",
    "        self.embed = nn.ParameterDict(embed_dict)\n",
    "        # create layers\n",
    "        self.layer1 = HeteroRGCNLayer(in_size, hidden_size, G.etypes)\n",
    "        self.layer2 = HeteroRGCNLayer(hidden_size, out_size, G.etypes)\n",
    "    \n",
    "    def forward(self, G):\n",
    "        h_dict = self.layer1(G, self.embed)\n",
    "        h_dict = {k : F.leaky_relu(h) for k, h in h_dict.items()}\n",
    "        h_dict = self.layer2(G, h_dict)\n",
    "        # get paper logits\n",
    "        return h_dict['paper']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('author', 'writing', 'paper'),\n ('paper', 'cited', 'paper'),\n ('paper', 'citing', 'paper'),\n ('paper', 'is-about', 'subject'),\n ('paper', 'written-by', 'author'),\n ('subject', 'has', 'paper')]"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "# Create the model. The output has three logits for three classes.\n",
    "G.canonical_etypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}